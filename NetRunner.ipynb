{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import os\n",
    "import pickle\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nAnchors = 24\n",
    "batchSize = 16\n",
    "numEpochs = 200\n",
    "device = \"cpu\"\n",
    "rng = np.random.default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, file, transform = None, target_transform=None):\n",
    "        super(AnchorDataSet, self).__init__()\n",
    "        self.df = pd.read_pickle(file).reset_index()\n",
    "        self.transform = transform\n",
    "        self.target_transform=target_transform\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        feats = self.df.loc[idx, \"Features\"].astype(np.double)\n",
    "        anchorDists = self.df.loc[idx, \"AnchorDists\"].astype(np.double)\n",
    "        \n",
    "        dofs = np.array([self.df.loc[idx,\"Z\"],self.df.loc[idx,\"W\"],self.df.loc[idx,\"P\"],self.df.loc[idx,\"Q\"],self.df.loc[idx,\"R\"]]).astype(np.double)\n",
    "        \n",
    "        xy = np.array([self.df.loc[idx,\"X\"], self.df.loc[idx,\"Y\"]]).astype(np.double)\n",
    "        imageFile = self.df.loc[idx, \"ImageFile\"]\n",
    "\n",
    "        return {\"Features\": feats,\n",
    "                \"anchorDists\": anchorDists,\n",
    "                \"dofs\": dofs,\n",
    "                \"xy\": xy,\n",
    "                \"ImageFile\": imageFile}\n",
    "\n",
    "\n",
    "class anchorNet(nn.Module):\n",
    "    def __init__(self, nAnchors):\n",
    "        super(anchorNet, self).__init__()\n",
    "        self.classifier = nn.Linear(2208, nAnchors)\n",
    "        self.regressor = nn.Linear(2208, 2*nAnchors)\n",
    "        self.dof_regressor = nn.Linear(2208, 5)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.double()\n",
    "    \n",
    "    def forward(self, feats):\n",
    "\n",
    "        classify = self.softmax(self.classifier(feats)) # TODO: ReLU useful?\n",
    "        regress = self.regressor(feats)\n",
    "        dof_regress = self.dof_regressor(feats)\n",
    "\n",
    "        return classify, regress, dof_regress\n",
    "\n",
    "class deepAnchorNet(nn.Module):\n",
    "    def __init__(self, nAnchors, dropout=0.3):\n",
    "        super(deepAnchorNet, self).__init__()\n",
    "        self.classifier = nn.ModuleList([nn.Linear(2208, 1104), nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(1104,700), nn.ReLU(), nn.Linear(700,350), nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(350, nAnchors)])\n",
    "        self.regressor = nn.ModuleList([nn.Linear(2208, 1104), nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(1104,700), nn.ReLU(), nn.Linear(700,350), nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(350, 2*nAnchors)])\n",
    "        self.dof_regressor = nn.Linear(2208, 5)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.double()\n",
    "    \n",
    "    def forward(self, feats):\n",
    "        c = nn.functional.relu(feats)\n",
    "        regress = nn.functional.relu(feats)\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            c = layer(c)\n",
    "\n",
    "        for layer in self.regressor:\n",
    "            regress = layer(regress)\n",
    "\n",
    "        classify = self.softmax(c) # TODO: ReLU useful?\n",
    "\n",
    "        dof_regress = self.dof_regressor(nn.functional.relu(feats))\n",
    "\n",
    "        return classify, regress, dof_regress\n",
    "\n",
    "def custom_loss(classify, regress, dof_regress, anchorDistsGt, dofGt, dofLoss, crossEntropy, factors = [2.4,0,0.5]):\n",
    "    # TODO: Possible Flaw (or the reason why this works?):\n",
    "    # The net tries to learn realtive position to each anchorpoint\n",
    "    # independently, so we have a large amount of degrees of freedom, even though relative\n",
    "    # position to anchor points should have 2 DOF. Maybe try using more anchorpoints to\n",
    "    # proof this point.\n",
    "\n",
    "    \"\"\"\n",
    "    classify: output of anchor classifier\n",
    "    regress: output of regressor\n",
    "    dof_regress: output of dof_regressor\n",
    "    anchorDistsGt: true distance to all anchor poitns\n",
    "    dofGt: true remaining 4 DOF\n",
    "    dofLoss: loss function used for dof_regressor\n",
    "    factors: list of hyperparameters for weighting of different loss terms\n",
    "    \"\"\"\n",
    "\n",
    "    dist = (regress.reshape(-1, nAnchors, 2) - anchorDistsGt)\n",
    "\n",
    "    # TODO: Use softmax on gt-dof and dof for normalization\n",
    "    \n",
    "    lossXY = torch.sum(torch.linalg.norm(dist, axis = -1) * classify)\n",
    "    \n",
    "    nearest = torch.argmin(torch.linalg.norm(anchorDistsGt, axis=-1), axis=-1)\n",
    "\n",
    "    if rng.permutation(500)[0] == 0:\n",
    "        print(\"Cross Entropy Loss of classifier: \", crossEntropy(classify, nearest).cpu().detach().data.item())\n",
    "\n",
    "    return factors[0] * lossXY + factors[1]*crossEntropy(classify, nearest) + factors[2] * dofLoss(dof_regress, dofGt), crossEntropy(classify, nearest).cpu().detach().data.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0:  3033.851497534458\n",
      "Training Dist:  11.694453017161859 m\n",
      "z dist:  -1.0959156628090518 m, dof dist:  14.242773484451796 °\n",
      "Cross Entropy Loss of classifier:  3.226491779238793\n",
      "Cross Entropy Loss of classifier:  3.230661961180238\n",
      "Cross Entropy Loss of classifier:  3.230731148890851\n",
      "Cross Entropy Loss of classifier:  3.1683330086036627\n",
      "Loss in epoch 100:  2391.4662095097456\n",
      "Training Dist:  10.266821369358336 m\n",
      "z dist:  1.4594345721152812e-06 m, dof dist:  98.27530096964111 °\n",
      "Cross Entropy Loss of classifier:  3.2307560236349664\n",
      "Cross Entropy Loss of classifier:  3.2307702362886515\n",
      "Cross Entropy Loss of classifier:  3.230737382147008\n",
      "Cross Entropy Loss of classifier:  3.2307721034027357\n",
      "Loss in epoch 0:  2985.532964525952\n",
      "Training Dist:  10.750584907853952 m\n",
      "z dist:  -0.6831884885323505 m, dof dist:  25.703866282965418 °\n",
      "Cross Entropy Loss of classifier:  3.2290557192801526\n",
      "Cross Entropy Loss of classifier:  3.2306336457025977\n",
      "Cross Entropy Loss of classifier:  3.230742498273551\n",
      "Loss in epoch 100:  2392.816320504435\n",
      "Training Dist:  10.34205118533185 m\n",
      "z dist:  4.6911946174457806e-05 m, dof dist:  99.74303449514606 °\n",
      "Cross Entropy Loss of classifier:  3.229028096245258\n",
      "Cross Entropy Loss of classifier:  3.2311465717934302\n",
      "Cross Entropy Loss of classifier:  3.231184986383681\n",
      "Cross Entropy Loss of classifier:  3.2316553498862874\n",
      "Loss in epoch 0:  3057.1627673386292\n",
      "Training Dist:  10.449647425186177 m\n",
      "z dist:  -1.1783692787616995 m, dof dist:  10.566860860842613 °\n",
      "Cross Entropy Loss of classifier:  2.1558845581664827\n",
      "Cross Entropy Loss of classifier:  2.1536068408696845\n",
      "Cross Entropy Loss of classifier:  2.426355934196744\n",
      "Loss in epoch 100:  2390.2797301122346\n",
      "Training Dist:  10.260695867757835 m\n",
      "z dist:  4.5444935723337744e-06 m, dof dist:  98.35445997763321 °\n",
      "Cross Entropy Loss of classifier:  2.3245128133277535\n",
      "Loss in epoch 0:  3146.166252670472\n",
      "Training Dist:  11.728138038623563 m\n",
      "z dist:  -1.0543777556285472 m, dof dist:  59.19666282680044 °\n",
      "Cross Entropy Loss of classifier:  3.531206539649765\n",
      "Cross Entropy Loss of classifier:  3.544885412942964\n",
      "Cross Entropy Loss of classifier:  3.5453429332139437\n",
      "Cross Entropy Loss of classifier:  3.5444951075829616\n",
      "Loss in epoch 100:  2390.046131839821\n",
      "Training Dist:  10.260790945064663 m\n",
      "z dist:  5.398389340338649e-06 m, dof dist:  98.35461754813407 °\n",
      "Cross Entropy Loss of classifier:  3.546045776100124\n",
      "Loss in epoch 0:  2925.9347864914234\n",
      "Training Dist:  10.758633140335569 m\n",
      "z dist:  -0.15990538035346183 m, dof dist:  -7.039654438341118 °\n",
      "Cross Entropy Loss of classifier:  3.225121485400138\n",
      "Cross Entropy Loss of classifier:  3.1659357114914135\n",
      "Cross Entropy Loss of classifier:  3.2252241389082132\n",
      "Loss in epoch 100:  2392.182373168637\n",
      "Training Dist:  10.270634963557592 m\n",
      "z dist:  -7.663854014298515e-06 m, dof dist:  98.22558725789236 °\n",
      "Cross Entropy Loss of classifier:  3.1876203374336587\n",
      "Cross Entropy Loss of classifier:  3.225235319020933\n",
      "Cross Entropy Loss of classifier:  3.2201038450083375\n",
      "Cross Entropy Loss of classifier:  3.225238888831232\n",
      "Cross Entropy Loss of classifier:  3.0653051664503725\n",
      "Cross Entropy Loss of classifier:  3.210172990829645\n",
      "Loss in epoch 0:  3085.8834786527577\n",
      "Training Dist:  15.327275960292218 m\n",
      "z dist:  -1.7386700063024516 m, dof dist:  -64.66570912296827 °\n",
      "Cross Entropy Loss of classifier:  3.2313935686349944\n",
      "Cross Entropy Loss of classifier:  3.241589882907004\n",
      "Cross Entropy Loss of classifier:  3.245346141154979\n",
      "Cross Entropy Loss of classifier:  3.2449248148680407\n",
      "Cross Entropy Loss of classifier:  3.2421507493612776\n",
      "Cross Entropy Loss of classifier:  3.2423438333710073\n",
      "Loss in epoch 100:  2390.1834893242994\n",
      "Training Dist:  10.255048349148451 m\n",
      "z dist:  2.0366401844329475e-06 m, dof dist:  98.36534081146804 °\n",
      "Cross Entropy Loss of classifier:  2.6937705152957148\n",
      "Cross Entropy Loss of classifier:  3.183600572782415\n",
      "Cross Entropy Loss of classifier:  3.1836715425237316\n",
      "Cross Entropy Loss of classifier:  3.2461675966953836\n",
      "Loss in epoch 0:  3054.27686428095\n",
      "Training Dist:  11.225223873361337 m\n",
      "z dist:  -1.314128474548408 m, dof dist:  -0.1248174822436918 °\n",
      "Cross Entropy Loss of classifier:  3.169821731138497\n",
      "Cross Entropy Loss of classifier:  3.2343425343841745\n",
      "Loss in epoch 100:  2392.474399604098\n",
      "Training Dist:  10.271269998841941 m\n",
      "z dist:  -4.927054389810189e-06 m, dof dist:  98.15358694097952 °\n",
      "Cross Entropy Loss of classifier:  3.2348460166056134\n",
      "Cross Entropy Loss of classifier:  3.234829609952086\n",
      "Cross Entropy Loss of classifier:  3.1731928323730028\n",
      "Loss in epoch 0:  3045.2440567038166\n",
      "Training Dist:  10.974492438364974 m\n",
      "z dist:  -1.3635024021786957 m, dof dist:  25.154346837739617 °\n",
      "Cross Entropy Loss of classifier:  3.2323526620908076\n",
      "Cross Entropy Loss of classifier:  3.232477946042679\n",
      "Cross Entropy Loss of classifier:  3.23254137790778\n",
      "Loss in epoch 100:  2389.5101100189595\n",
      "Training Dist:  10.258525718741152 m\n",
      "z dist:  4.781663832688817e-06 m, dof dist:  98.36368999292588 °\n",
      "Cross Entropy Loss of classifier:  3.2327641437248325\n",
      "Loss in epoch 0:  2931.639294992531\n",
      "Training Dist:  11.978060870968095 m\n",
      "z dist:  -0.3581867119360562 m, dof dist:  16.414689326553386 °\n",
      "Cross Entropy Loss of classifier:  1.5101411223571661\n",
      "Cross Entropy Loss of classifier:  2.4528223226284496\n",
      "Cross Entropy Loss of classifier:  2.424506802878282\n",
      "Cross Entropy Loss of classifier:  2.452845073273684\n",
      "Cross Entropy Loss of classifier:  2.4529809620973744\n",
      "Cross Entropy Loss of classifier:  2.412355954339822\n",
      "Cross Entropy Loss of classifier:  2.453079224360229\n",
      "Cross Entropy Loss of classifier:  2.453133917746123\n",
      "Cross Entropy Loss of classifier:  2.450233117823613\n",
      "Cross Entropy Loss of classifier:  2.4532188397720436\n",
      "Loss in epoch 100:  2401.156745961161\n",
      "Training Dist:  10.374848632254565 m\n",
      "z dist:  0.0001782993101799321 m, dof dist:  67.74683440623429 °\n",
      "Cross Entropy Loss of classifier:  2.453319786098157\n",
      "Cross Entropy Loss of classifier:  2.4533083253504033\n",
      "Cross Entropy Loss of classifier:  2.45336012303836\n",
      "Cross Entropy Loss of classifier:  2.4533819909039445\n",
      "Cross Entropy Loss of classifier:  2.4534337330038785\n",
      "Cross Entropy Loss of classifier:  2.453459610364103\n",
      "Cross Entropy Loss of classifier:  2.453661490670803\n",
      "Cross Entropy Loss of classifier:  2.4537049087108116\n",
      "Cross Entropy Loss of classifier:  2.453764888268023\n",
      "Cross Entropy Loss of classifier:  2.453876824569754\n",
      "Cross Entropy Loss of classifier:  2.4540425588955714\n",
      "Cross Entropy Loss of classifier:  2.4543573157045637\n",
      "Loss in epoch 0:  3144.57954280377\n",
      "Training Dist:  11.673768084222274 m\n",
      "z dist:  -1.6296539759915802 m, dof dist:  18.26330297344342 °\n",
      "Cross Entropy Loss of classifier:  2.374716052601841\n",
      "Cross Entropy Loss of classifier:  2.339373800889812\n",
      "Cross Entropy Loss of classifier:  2.289002390400151\n",
      "Loss in epoch 100:  2392.5304127753875\n",
      "Training Dist:  10.26366168074776 m\n",
      "z dist:  2.4817931923123057e-06 m, dof dist:  98.36532015256672 °\n",
      "Cross Entropy Loss of classifier:  2.293117446308208\n",
      "Cross Entropy Loss of classifier:  2.422684257047183\n",
      "Cross Entropy Loss of classifier:  2.4229215300776072\n",
      "Cross Entropy Loss of classifier:  2.4229261155156134\n",
      "Cross Entropy Loss of classifier:  2.4219035655703047\n",
      "Cross Entropy Loss of classifier:  2.42194683102115\n",
      "Loss in epoch 0:  3021.8410429645455\n",
      "Training Dist:  10.589508879021727 m\n",
      "z dist:  -0.9452076106402532 m, dof dist:  59.182534542135635 °\n",
      "Cross Entropy Loss of classifier:  2.4139785269904257\n",
      "Cross Entropy Loss of classifier:  2.441566040528731\n",
      "Cross Entropy Loss of classifier:  2.442778354403288\n",
      "Cross Entropy Loss of classifier:  2.376804387403348\n",
      "Cross Entropy Loss of classifier:  2.4403161759939627\n",
      "Cross Entropy Loss of classifier:  2.4436753102565323\n",
      "Cross Entropy Loss of classifier:  2.4434224998488983\n",
      "Cross Entropy Loss of classifier:  2.443716414188157\n",
      "Cross Entropy Loss of classifier:  2.443959621225974\n",
      "Cross Entropy Loss of classifier:  2.444401130231922\n",
      "Cross Entropy Loss of classifier:  2.444506956486468\n",
      "Cross Entropy Loss of classifier:  2.444149417948114\n",
      "Cross Entropy Loss of classifier:  2.4443225259953505\n",
      "Cross Entropy Loss of classifier:  1.5731093427944987\n",
      "Loss in epoch 100:  2394.5332581592584\n",
      "Training Dist:  10.347713571820755 m\n",
      "z dist:  0.0001998607160719584 m, dof dist:  99.83194300482698 °\n",
      "Cross Entropy Loss of classifier:  2.445050480029374\n",
      "Cross Entropy Loss of classifier:  2.3873190799067956\n",
      "Cross Entropy Loss of classifier:  2.4480857182393683\n",
      "Cross Entropy Loss of classifier:  2.7982363364264597\n",
      "Loss in epoch 0:  2942.238552946237\n",
      "Training Dist:  10.58725109351411 m\n",
      "z dist:  -0.7758651917891184 m, dof dist:  11.114221625115901 °\n",
      "Cross Entropy Loss of classifier:  2.869157406953021\n",
      "Cross Entropy Loss of classifier:  2.8739809085955494\n",
      "Cross Entropy Loss of classifier:  2.874061475379439\n",
      "Cross Entropy Loss of classifier:  2.8742341507309104\n",
      "Cross Entropy Loss of classifier:  2.874323139489146\n",
      "Cross Entropy Loss of classifier:  2.8741564564954576\n",
      "Cross Entropy Loss of classifier:  2.874378911162852\n",
      "Cross Entropy Loss of classifier:  2.87447022321268\n",
      "Cross Entropy Loss of classifier:  2.8744730930757036\n",
      "Cross Entropy Loss of classifier:  2.6246938191295968\n",
      "Cross Entropy Loss of classifier:  2.8744953084344793\n",
      "Cross Entropy Loss of classifier:  2.8744914793953047\n",
      "Cross Entropy Loss of classifier:  2.8744981219105608\n",
      "Loss in epoch 100:  2394.4461192270724\n",
      "Training Dist:  10.347596430405298 m\n",
      "z dist:  0.00020039950649168294 m, dof dist:  99.83194449271335 °\n",
      "Cross Entropy Loss of classifier:  2.8745153181016936\n",
      "Cross Entropy Loss of classifier:  2.874516171948062\n",
      "Cross Entropy Loss of classifier:  2.8745231212812192\n",
      "Cross Entropy Loss of classifier:  2.874486966585554\n",
      "Cross Entropy Loss of classifier:  2.874541114832023\n",
      "Cross Entropy Loss of classifier:  2.8745417950286214\n",
      "Cross Entropy Loss of classifier:  2.374738873167159\n",
      "Cross Entropy Loss of classifier:  2.874546242210716\n",
      "Cross Entropy Loss of classifier:  2.874553164044656\n",
      "Cross Entropy Loss of classifier:  2.8745449898606674\n",
      "Cross Entropy Loss of classifier:  2.8745633577873564\n",
      "Loss in epoch 0:  3012.1738731578425\n",
      "Training Dist:  10.720201982413151 m\n",
      "z dist:  -1.2088447222365801 m, dof dist:  53.11108568935675 °\n",
      "Cross Entropy Loss of classifier:  3.2368461125134127\n",
      "Cross Entropy Loss of classifier:  3.2376458013839056\n",
      "Cross Entropy Loss of classifier:  3.2376165870964337\n",
      "Cross Entropy Loss of classifier:  3.237634138607649\n",
      "Cross Entropy Loss of classifier:  3.237710899460519\n",
      "Cross Entropy Loss of classifier:  3.2380003183593806\n",
      "Cross Entropy Loss of classifier:  3.2382105095900404\n",
      "Cross Entropy Loss of classifier:  3.028485096465425\n",
      "Cross Entropy Loss of classifier:  3.2382007196931903\n",
      "Cross Entropy Loss of classifier:  3.238934518912684\n",
      "Loss in epoch 100:  2394.466609455327\n",
      "Training Dist:  10.347694734754906 m\n",
      "z dist:  0.00019871413115176448 m, dof dist:  99.83194576751366 °\n",
      "Cross Entropy Loss of classifier:  3.2392033770753033\n",
      "Cross Entropy Loss of classifier:  3.2391556855868577\n",
      "Cross Entropy Loss of classifier:  3.2392341183765647\n",
      "Cross Entropy Loss of classifier:  3.239381825359109\n",
      "Cross Entropy Loss of classifier:  3.2395031574401036\n",
      "Cross Entropy Loss of classifier:  3.239656082615745\n",
      "Cross Entropy Loss of classifier:  3.2398283375178036\n",
      "Cross Entropy Loss of classifier:  3.240077132907168\n",
      "Cross Entropy Loss of classifier:  3.240122646469456\n",
      "Cross Entropy Loss of classifier:  3.2406395647306208\n",
      "Loss in epoch 0:  2701.7946146104177\n",
      "Training Dist:  10.687221908982725 m\n",
      "z dist:  -0.30879542494226 m, dof dist:  2.009167309984766 °\n",
      "Cross Entropy Loss of classifier:  2.8579158373919515\n",
      "Cross Entropy Loss of classifier:  2.861445608153715\n",
      "Cross Entropy Loss of classifier:  2.009710718471461\n",
      "Cross Entropy Loss of classifier:  2.8584084742205893\n",
      "Cross Entropy Loss of classifier:  2.8620418760535142\n",
      "Cross Entropy Loss of classifier:  2.863043865552597\n",
      "Cross Entropy Loss of classifier:  2.862777962029239\n",
      "Cross Entropy Loss of classifier:  2.8624548082614343\n",
      "Cross Entropy Loss of classifier:  2.8631767685310443\n",
      "Cross Entropy Loss of classifier:  1.9897695917215676\n",
      "Cross Entropy Loss of classifier:  2.862761380976615\n",
      "Cross Entropy Loss of classifier:  2.8702254810622603\n",
      "Cross Entropy Loss of classifier:  2.8709606256268363\n",
      "Cross Entropy Loss of classifier:  2.8530298792924635\n",
      "Cross Entropy Loss of classifier:  2.8655466263217946\n",
      "Cross Entropy Loss of classifier:  2.8710655589133434\n",
      "Cross Entropy Loss of classifier:  2.866266151860403\n",
      "Cross Entropy Loss of classifier:  2.8704075500140567\n",
      "Cross Entropy Loss of classifier:  2.8638604153877045\n",
      "Cross Entropy Loss of classifier:  2.8581996493519384\n",
      "Cross Entropy Loss of classifier:  2.8657395519264965\n",
      "Cross Entropy Loss of classifier:  2.8641812731771283\n",
      "Cross Entropy Loss of classifier:  2.8605110121240256\n",
      "Cross Entropy Loss of classifier:  2.854142151381752\n",
      "Cross Entropy Loss of classifier:  2.8643117201221067\n",
      "Cross Entropy Loss of classifier:  2.863503587950504\n",
      "Cross Entropy Loss of classifier:  2.863700802485546\n",
      "Cross Entropy Loss of classifier:  2.86082153375523\n",
      "Cross Entropy Loss of classifier:  2.8595771399557126\n",
      "Cross Entropy Loss of classifier:  2.8510021675046477\n",
      "Cross Entropy Loss of classifier:  2.8627490532737525\n",
      "Cross Entropy Loss of classifier:  2.8597249143588512\n",
      "Cross Entropy Loss of classifier:  1.9878409934058479\n",
      "Cross Entropy Loss of classifier:  2.8546791387902326\n",
      "Cross Entropy Loss of classifier:  2.863065345021008\n",
      "Cross Entropy Loss of classifier:  2.8676362309198766\n",
      "Cross Entropy Loss of classifier:  2.854282306690564\n",
      "Cross Entropy Loss of classifier:  2.7530615910642977\n",
      "Cross Entropy Loss of classifier:  2.8582405261055124\n",
      "Cross Entropy Loss of classifier:  2.858594458315792\n",
      "Cross Entropy Loss of classifier:  2.865998931574513\n",
      "Cross Entropy Loss of classifier:  2.8643003982546325\n",
      "Cross Entropy Loss of classifier:  2.8629960109092094\n",
      "Cross Entropy Loss of classifier:  2.8625830585927687\n",
      "Cross Entropy Loss of classifier:  2.8621198679228126\n",
      "Cross Entropy Loss of classifier:  2.863260757477262\n",
      "Cross Entropy Loss of classifier:  2.859620012570096\n",
      "Cross Entropy Loss of classifier:  2.860569212171758\n",
      "Cross Entropy Loss of classifier:  2.856915317815183\n",
      "Cross Entropy Loss of classifier:  2.86080281721255\n",
      "Cross Entropy Loss of classifier:  2.8704684501580946\n",
      "Cross Entropy Loss of classifier:  2.8644393661436958\n",
      "Cross Entropy Loss of classifier:  2.8581924904361924\n",
      "Cross Entropy Loss of classifier:  2.8542335276294626\n",
      "Cross Entropy Loss of classifier:  2.561988747187013\n",
      "Cross Entropy Loss of classifier:  2.85387405970279\n",
      "Cross Entropy Loss of classifier:  2.85261503318335\n",
      "Cross Entropy Loss of classifier:  2.8537844478898466\n",
      "Cross Entropy Loss of classifier:  2.8526774864545845\n",
      "Cross Entropy Loss of classifier:  2.164646100979418\n",
      "Cross Entropy Loss of classifier:  2.8534539909621675\n",
      "Cross Entropy Loss of classifier:  2.85372786443143\n",
      "Cross Entropy Loss of classifier:  2.8533174321997734\n",
      "Cross Entropy Loss of classifier:  2.851966281276415\n",
      "Loss in epoch 100:  2413.3172451702653\n",
      "Training Dist:  10.386735675908305 m\n",
      "z dist:  0.00033487942785894 m, dof dist:  30.24654792443823 °\n",
      "Cross Entropy Loss of classifier:  2.8545376677999688\n",
      "Cross Entropy Loss of classifier:  2.853885118709027\n",
      "Cross Entropy Loss of classifier:  2.853897121762484\n",
      "Cross Entropy Loss of classifier:  2.851495225005309\n",
      "Cross Entropy Loss of classifier:  2.8535988647623447\n",
      "Cross Entropy Loss of classifier:  2.8484898674328236\n",
      "Cross Entropy Loss of classifier:  2.848923155303309\n",
      "Cross Entropy Loss of classifier:  2.853195340181291\n",
      "Cross Entropy Loss of classifier:  2.8483289866545305\n",
      "Cross Entropy Loss of classifier:  2.849753509528239\n",
      "Cross Entropy Loss of classifier:  2.8503837579868296\n",
      "Cross Entropy Loss of classifier:  2.8522308130016714\n",
      "Cross Entropy Loss of classifier:  2.8536865122648267\n",
      "Cross Entropy Loss of classifier:  2.8497027276213878\n",
      "Cross Entropy Loss of classifier:  2.8501728899114016\n",
      "Cross Entropy Loss of classifier:  2.8520887844363827\n",
      "Cross Entropy Loss of classifier:  2.8516636054550104\n",
      "Cross Entropy Loss of classifier:  2.851343738573832\n",
      "Cross Entropy Loss of classifier:  2.8513783640348342\n",
      "Cross Entropy Loss of classifier:  2.849279243977082\n",
      "Cross Entropy Loss of classifier:  2.3970050348443968\n",
      "Cross Entropy Loss of classifier:  2.2302577290513046\n",
      "Cross Entropy Loss of classifier:  2.8516303050938374\n",
      "Cross Entropy Loss of classifier:  2.851414144079632\n",
      "Cross Entropy Loss of classifier:  2.8511190587837647\n",
      "Cross Entropy Loss of classifier:  2.851617974261373\n",
      "Cross Entropy Loss of classifier:  2.8515799777039783\n",
      "Cross Entropy Loss of classifier:  2.48779356384948\n",
      "Cross Entropy Loss of classifier:  2.850362212157599\n",
      "Cross Entropy Loss of classifier:  2.851266392842758\n",
      "Cross Entropy Loss of classifier:  2.485977879413037\n",
      "Cross Entropy Loss of classifier:  2.8515554167437025\n",
      "Cross Entropy Loss of classifier:  2.851525418536853\n",
      "Cross Entropy Loss of classifier:  2.8510437577293595\n",
      "Cross Entropy Loss of classifier:  2.8512703113454627\n",
      "Cross Entropy Loss of classifier:  2.8511882348140634\n",
      "Cross Entropy Loss of classifier:  2.851151953628865\n",
      "Cross Entropy Loss of classifier:  2.851124650294114\n",
      "Cross Entropy Loss of classifier:  2.851236722966558\n",
      "Cross Entropy Loss of classifier:  2.8514805333499917\n",
      "Cross Entropy Loss of classifier:  2.851210905665607\n",
      "Cross Entropy Loss of classifier:  2.850777351387403\n",
      "Cross Entropy Loss of classifier:  2.851086718616055\n",
      "Cross Entropy Loss of classifier:  2.8502348376290243\n",
      "Cross Entropy Loss of classifier:  2.851631115668889\n",
      "Cross Entropy Loss of classifier:  2.8509792012501514\n",
      "Cross Entropy Loss of classifier:  2.8511643270641702\n",
      "Cross Entropy Loss of classifier:  2.8487706060586477\n",
      "Cross Entropy Loss of classifier:  2.8509627146815424\n",
      "Cross Entropy Loss of classifier:  2.8496218886887257\n",
      "Cross Entropy Loss of classifier:  2.850890014228117\n",
      "Loss in epoch 0:  3011.3101340237527\n",
      "Training Dist:  10.522103204613312 m\n",
      "z dist:  -1.2254083327142171 m, dof dist:  59.8734542629577 °\n",
      "Cross Entropy Loss of classifier:  2.3934863585648865\n",
      "Cross Entropy Loss of classifier:  2.3879438315035135\n",
      "Cross Entropy Loss of classifier:  2.433455445318593\n",
      "Cross Entropy Loss of classifier:  2.4330846669417623\n",
      "Cross Entropy Loss of classifier:  2.3231477798712876\n",
      "Cross Entropy Loss of classifier:  2.433997236857169\n",
      "Cross Entropy Loss of classifier:  2.212975700841241\n",
      "Cross Entropy Loss of classifier:  2.4344571254314973\n",
      "Cross Entropy Loss of classifier:  2.4347352622458356\n",
      "Cross Entropy Loss of classifier:  2.4354292892859872\n",
      "Cross Entropy Loss of classifier:  2.2244943507729875\n",
      "Cross Entropy Loss of classifier:  2.4363275748082573\n",
      "Loss in epoch 100:  2394.5366612329663\n",
      "Training Dist:  10.34771271735891 m\n",
      "z dist:  0.00019862820145794373 m, dof dist:  99.8319597817047 °\n",
      "Cross Entropy Loss of classifier:  2.3342028843717477\n",
      "Cross Entropy Loss of classifier:  2.4366699686735003\n",
      "Cross Entropy Loss of classifier:  2.436884777451321\n",
      "Cross Entropy Loss of classifier:  2.4371273409829106\n",
      "Cross Entropy Loss of classifier:  2.437570762481439\n",
      "Cross Entropy Loss of classifier:  2.4379356539092254\n",
      "Cross Entropy Loss of classifier:  2.4377369993310216\n",
      "Cross Entropy Loss of classifier:  2.438136494816928\n",
      "Cross Entropy Loss of classifier:  2.4388213070728675\n"
     ]
    }
   ],
   "source": [
    "numEpochs = 200\n",
    "hyperparameters = {\"setting1\": [24, 16, 0.0003, 0.5],\n",
    "                    \"setting2\": [24, 8, 0.0003, 0.2],\n",
    "                    \"setting3\": [10, 16, 0.0003, 0.2],\n",
    "                    \"setting4\": [33, 16, 0.0003, 0.2],\n",
    "                    \"setting5\": [24, 16, 0.001, 0.2],\n",
    "                    \"setting6\": [24, 16, 0.0001, 0.2],\n",
    "                    \"setting7\": [24, 16, 0.0003, 0.7],\n",
    "                    \"setting8\": [24, 16, 0.0003, 0.1],\n",
    "                    \"setting9\": [10, 4, 0.0003, 0.2],\n",
    "                    \"setting10\": [10, 16, 0.0001, 0.2],\n",
    "                    \"setting11\": [10, 4, 0.0001, 0.2],\n",
    "                    \"setting12\": [16, 4, 0.0001, 0.2],\n",
    "                    \"setting13\": [24, 4, 0.0001, 0.2],\n",
    "                    \"setting14\": [16, 1, 0.0001, 0.2],\n",
    "                    \"setting15\": [10, 4, 0.0001, 0.2],\n",
    "                    }\n",
    "\n",
    "for hp in list(hyperparameters.keys()):\n",
    "\n",
    "    nAnchors = hyperparameters[hp][0]\n",
    "    batchSize = hyperparameters[hp][1]\n",
    "    learningRate = hyperparameters[hp][2]\n",
    "    gamma = hyperparameters[hp][3]\n",
    "\n",
    "    trainDataset = AnchorDataSet(file= f\"./ShopFacade/traindata_with_features_and_anchors{nAnchors}.pkl\")\n",
    "    trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=batchSize, shuffle=False, num_workers=0)\n",
    "\n",
    "    testDataset = AnchorDataSet(file= f\"./ShopFacade/testdata_with_features_and_anchors{nAnchors}.pkl\")\n",
    "    testDataloader = torch.utils.data.DataLoader(testDataset, batch_size=batchSize, shuffle=False, num_workers=0)\n",
    "\n",
    "    myNet = anchorNet(nAnchors=nAnchors).to(device)\n",
    "    dofLoss = nn.MSELoss().to(device)\n",
    "    crossEntropy = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(myNet.parameters(), lr=learningRate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=gamma)\n",
    "\n",
    "    myAnchors = torch.from_numpy(np.loadtxt(f\"./ShopFacade/anchors{nAnchors}.txt\")).to(device)\n",
    "\n",
    "    epochs = []\n",
    "    testXY = []\n",
    "    testZ = []\n",
    "    testRot = []\n",
    "    trainLoss = np.zeros(numEpochs)\n",
    "    trainCELoss = np.zeros(numEpochs)\n",
    "\n",
    "    for epoch in range(numEpochs):\n",
    "        epochLoss = 0\n",
    "        trainDists = []\n",
    "        zTrain = []\n",
    "        dofTrain = []\n",
    "\n",
    "        for i, data in enumerate(trainDataloader):\n",
    "\n",
    "            myNet.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            myFeats = data[\"Features\"]\n",
    "            myFeats = myFeats.to(device)\n",
    "\n",
    "            myAnchorDistsGt = data[\"anchorDists\"]\n",
    "            myAnchorDistsGt = myAnchorDistsGt.to(device)\n",
    "\n",
    "            myDofGt = data[\"dofs\"]\n",
    "            myDofGt = myDofGt.to(device)\n",
    "\n",
    "            myXyGt = data[\"xy\"]\n",
    "            myXyGt = myXyGt.to(device)\n",
    "\n",
    "            classify, regress, dof_regress = myNet.forward(myFeats)\n",
    "            loss, cEntLoss = custom_loss(classify, regress, dof_regress, anchorDistsGt=myAnchorDistsGt, dofGt=myDofGt, dofLoss=dofLoss, crossEntropy=crossEntropy, factors=[1,0,1])\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            dLoss = loss.data.item()\n",
    "            epochLoss += dLoss\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                bestAnchor = torch.argmax(classify, axis=1).to(device)\n",
    "\n",
    "                dist = 0\n",
    "                dofDist = 0\n",
    "\n",
    "                for j in range(bestAnchor.size()[0]):\n",
    "                    dist += torch.linalg.norm(torch.abs((myAnchors[bestAnchor[j], :] - regress.reshape(-1,nAnchors,2)[j,bestAnchor[j], :]) - (myXyGt)[j]))\n",
    "                    dofDist += np.mean(Rotation.from_quat(dof_regress[j,1:].cpu().detach().numpy()).as_euler(\"xyz\", degrees=True) - Rotation.from_quat(myDofGt[j,1:].cpu().detach().numpy()).as_euler(\"xyz\",degrees=True))\n",
    "\n",
    "                trainDists.append(dist.data.item() / bestAnchor.size()[0])\n",
    "                zTrain.append(torch.mean(dof_regress[:,0] - myDofGt[:,0]).data.item())\n",
    "                dofTrain.append(dofDist/bestAnchor.size()[0])\n",
    "\n",
    "                trainLoss[epoch] += dLoss\n",
    "                trainCELoss[epoch] += cEntLoss\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch)%100==0:\n",
    "\n",
    "            print(f\"Loss in epoch {epoch}: \", epochLoss)\n",
    "            print(\"Training Dist: \", np.mean(trainDists),\"m\")\n",
    "            print(\"z dist: \", np.mean(zTrain), \"m, dof dist: \", np.mean(dofTrain), \"°\")\n",
    "\n",
    "        # ===========TESTING=============\n",
    "\n",
    "        if epoch%5 == 0:\n",
    "            \n",
    "            epochs.append(epoch)    \n",
    "            testDists = []\n",
    "            zTest = []\n",
    "            dofTest = []\n",
    "\n",
    "            for idx, data in enumerate(testDataloader):\n",
    "\n",
    "                myNet.eval()\n",
    "\n",
    "                myFeats = data[\"Features\"]\n",
    "                myFeats = myFeats.to(device)\n",
    "\n",
    "                myAnchorDistsGt = data[\"anchorDists\"]\n",
    "                myAnchorDistsGt = myAnchorDistsGt.to(device)\n",
    "\n",
    "                myDofGt = data[\"dofs\"]\n",
    "                myDofGt = myDofGt.to(device)\n",
    "\n",
    "                myXyGt = data[\"xy\"]\n",
    "                myXyGt = myXyGt.to(device)\n",
    "\n",
    "                classify, regress, dof_regress = myNet.forward(myFeats)\n",
    "                \n",
    "                bestAnchor = torch.argmax(classify, axis=1).to(device)\n",
    "\n",
    "                dist = 0\n",
    "                dofDist = 0\n",
    "\n",
    "                for j in range(bestAnchor.size()[0]):\n",
    "                    dist += torch.linalg.norm(torch.abs((myAnchors[bestAnchor[j], :] - regress.reshape(-1,nAnchors,2)[j,bestAnchor[j], :]) - (myXyGt)[j]))\n",
    "                    dofDist += np.mean(Rotation.from_quat(dof_regress[j,1:].cpu().detach().numpy()).as_euler(\"xyz\", degrees=True) - Rotation.from_quat(myDofGt[j,1:].cpu().detach().numpy()).as_euler(\"xyz\",degrees=True))\n",
    "\n",
    "                testDists.append(dist.data.item() / bestAnchor.size()[0])\n",
    "                zTest.append(torch.mean(dof_regress[:,0] - myDofGt[:,0]).data.item())\n",
    "                dofTest.append(dofDist/bestAnchor.size()[0])\n",
    "            \n",
    "            testXY.append(np.mean(testDists))\n",
    "            testZ.append(np.mean(zTest))\n",
    "            testRot.append(np.mean(dofTest))\n",
    "\n",
    "    testResults = pd.DataFrame(data={\"Epochs\":epochs, \"XY_dist\":testXY, \"Z_Dist\":testZ,\"angle_error\":testRot})\n",
    "    testResults.to_csv(f\"./ShopFacade/testResults_with_{nAnchors}anchors_{hp}.csv\")\n",
    "\n",
    "    lossDf = pd.DataFrame(data={\"TotalLoss\": trainLoss, \"CrossEntropyLoss\":trainCELoss})\n",
    "    lossDf.to_csv(f\"./ShopFacade/trainLoss_with_{nAnchors}anchors_{hp}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Classifier seems to be trash, can't be trained to be better with cross entropy.\n",
    "- loss from regressor term doesn't seem to shrink either\n",
    "- mixed regressor/classifier-loss term doesn't help classifier to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testResults = pd.read_csv(\"./ShopFacade/trai\")\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(testResults[\"Epochs\"], testResults[\"XY_dist\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0:  3056.6000895128955\n",
      "Training Dist:  11.692224229985857 m\n",
      "z dist:  -1.4412297682028539 m, dof dist:  -73.19345701136044 °\n",
      "Cross Entropy Loss of classifier:  3.188328233625012\n",
      "Cross Entropy Loss of classifier:  3.2462960397757366\n",
      "Cross Entropy Loss of classifier:  3.1222337354302585\n",
      "Cross Entropy Loss of classifier:  3.2471086670514566\n",
      "Cross Entropy Loss of classifier:  3.247147090813976\n",
      "Cross Entropy Loss of classifier:  3.2471758485033044\n",
      "Cross Entropy Loss of classifier:  3.247186360249322\n",
      "Cross Entropy Loss of classifier:  3.247193441744151\n",
      "Loss in epoch 100:  2395.2476125788494\n",
      "Training Dist:  10.365342421878198 m\n",
      "z dist:  -0.0036601167331546244 m, dof dist:  98.99907344119319 °\n",
      "Cross Entropy Loss of classifier:  3.2472009656713037\n",
      "Cross Entropy Loss of classifier:  3.247196869406217\n",
      "Cross Entropy Loss of classifier:  3.2472009674095283\n"
     ]
    }
   ],
   "source": [
    "nAnchors = 24\n",
    "batchSize = 8\n",
    "learningRate = 0.00005\n",
    "gamma = 0.5\n",
    "numEpochs = 200\n",
    "\n",
    "trainDataset = AnchorDataSet(file= f\"./ShopFacade/traindata_with_features_and_anchors{nAnchors}.pkl\")\n",
    "trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=batchSize, shuffle=True, num_workers=0)\n",
    "\n",
    "testDataset = AnchorDataSet(file= f\"./ShopFacade/testdata_with_features_and_anchors{nAnchors}.pkl\")\n",
    "testDataloader = torch.utils.data.DataLoader(testDataset, batch_size=batchSize, shuffle=True, num_workers=0)\n",
    "\n",
    "myNet = deepAnchorNet(nAnchors=nAnchors).to(device)\n",
    "dofLoss = nn.MSELoss().to(device)\n",
    "crossEntropy = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(myNet.parameters(), lr=learningRate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=gamma)\n",
    "\n",
    "myAnchors = torch.from_numpy(np.loadtxt(f\"./ShopFacade/anchors{nAnchors}.txt\")).to(device)\n",
    "\n",
    "epochs = []\n",
    "testXY = []\n",
    "testZ = []\n",
    "testRot = []\n",
    "trainLoss = []\n",
    "trainCELoss = []\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    epochLoss = 0\n",
    "    trainDists = []\n",
    "    zTrain = []\n",
    "    dofTrain = []\n",
    "\n",
    "    for i, data in enumerate(trainDataloader):\n",
    "\n",
    "        myNet.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        myFeats = data[\"Features\"]\n",
    "        myFeats = myFeats.to(device)\n",
    "\n",
    "        myAnchorDistsGt = data[\"anchorDists\"]\n",
    "        myAnchorDistsGt = myAnchorDistsGt.to(device)\n",
    "\n",
    "        myDofGt = data[\"dofs\"]\n",
    "        myDofGt = myDofGt.to(device)\n",
    "\n",
    "        myXyGt = data[\"xy\"]\n",
    "        myXyGt = myXyGt.to(device)\n",
    "\n",
    "        classify, regress, dof_regress = myNet.forward(myFeats)\n",
    "        loss, cEntLoss = custom_loss(classify, regress, dof_regress, anchorDistsGt=myAnchorDistsGt, dofGt=myDofGt, dofLoss=dofLoss, crossEntropy=crossEntropy, factors=[1,0,1])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        dLoss = loss.data.item()\n",
    "        epochLoss += dLoss\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            bestAnchor = torch.argmax(classify, axis=1).to(device)\n",
    "\n",
    "            dist = 0\n",
    "            dofDist = 0\n",
    "\n",
    "            for j in range(bestAnchor.size()[0]):\n",
    "                dist += torch.linalg.norm(torch.abs((myAnchors[bestAnchor[j], :] - regress.reshape(-1,nAnchors,2)[j,bestAnchor[j], :]) - (myXyGt)[j]))\n",
    "                dofDist += np.mean(Rotation.from_quat(dof_regress[j,1:].cpu().detach().numpy()).as_euler(\"xyz\", degrees=True) - Rotation.from_quat(myDofGt[j,1:].cpu().detach().numpy()).as_euler(\"xyz\",degrees=True))\n",
    "\n",
    "            trainDists.append(dist.data.item() / bestAnchor.size()[0])\n",
    "            zTrain.append(torch.mean(dof_regress[:,0] - myDofGt[:,0]).data.item())\n",
    "            dofTrain.append(dofDist/bestAnchor.size()[0])\n",
    "\n",
    "            trainLoss.append(dLoss)\n",
    "            trainCELoss.append(cEntLoss)\n",
    "\n",
    "\n",
    "    scheduler.step()     \n",
    "    if (epoch)%100==0:\n",
    "\n",
    "        print(f\"Loss in epoch {epoch}: \", epochLoss)\n",
    "        print(\"Training Dist: \", np.mean(trainDists),\"m\")\n",
    "        print(\"z dist: \", np.mean(zTrain), \"m, dof dist: \", np.mean(dofTrain), \"°\")\n",
    "\n",
    "    # ===========TESTING=============\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        epochs.append(epoch)    \n",
    "        testDists = []\n",
    "        zTest = []\n",
    "        dofTest = []\n",
    "\n",
    "        for idx, data in enumerate(testDataloader):\n",
    "\n",
    "            myNet.eval()\n",
    "\n",
    "            myFeats = data[\"Features\"]\n",
    "            myFeats = myFeats.to(device)\n",
    "\n",
    "            myAnchorDistsGt = data[\"anchorDists\"]\n",
    "            myAnchorDistsGt = myAnchorDistsGt.to(device)\n",
    "\n",
    "            myDofGt = data[\"dofs\"]\n",
    "            myDofGt = myDofGt.to(device)\n",
    "\n",
    "            myXyGt = data[\"xy\"]\n",
    "            myXyGt = myXyGt.to(device)\n",
    "\n",
    "            classify, regress, dof_regress = myNet.forward(myFeats)\n",
    "            \n",
    "            bestAnchor = torch.argmax(classify, axis=1).to(device)\n",
    "\n",
    "            dist = 0\n",
    "            dofDist = 0\n",
    "\n",
    "            for j in range(bestAnchor.size()[0]):\n",
    "                dist += torch.linalg.norm(torch.abs((myAnchors[bestAnchor[j], :] - regress.reshape(-1,nAnchors,2)[j,bestAnchor[j], :]) - (myXyGt)[j]))\n",
    "                dofDist += np.mean(Rotation.from_quat(dof_regress[j,1:].cpu().detach().numpy()).as_euler(\"xyz\", degrees=True) - Rotation.from_quat(myDofGt[j,1:].cpu().detach().numpy()).as_euler(\"xyz\",degrees=True))\n",
    "\n",
    "            testDists.append(dist.data.item() / bestAnchor.size()[0])\n",
    "            zTest.append(torch.mean(dof_regress[:,0] - myDofGt[:,0]).data.item())\n",
    "            dofTest.append(dofDist/bestAnchor.size()[0])\n",
    "        \n",
    "        testXY.append(np.mean(testDists))\n",
    "        testZ.append(np.mean(zTest))\n",
    "        testRot.append(np.mean(dofTest))\n",
    "\n",
    "testResults = pd.DataFrame(data={\"Epochs\":epochs, \"XY_dist\":testXY, \"Z_Dist\":testZ,\"angle_error\":testRot})\n",
    "testResults.to_csv(f\"./ShopFacade/deepTestResults_with_{nAnchors}anchors_shuffle.csv\")\n",
    "\n",
    "lossDf = pd.DataFrame(data={\"TotalLoss\": trainLoss, \"CrossEntropyLoss\":trainCELoss})\n",
    "lossDf.to_csv(f\"./ShopFacade/deepTrainLoss_with_{nAnchors}anchors_shuffle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss of classifier:  3.2128696871881663\n",
      "Cross Entropy Loss of classifier:  3.148889985730453\n",
      "Cross Entropy Loss of classifier:  3.229390583062703\n",
      "Cross Entropy Loss of classifier:  3.07705169544591\n",
      "Loss in epoch 99:  20241.01608518687\n",
      "Training Dist:  21.48697679888505 m\n",
      "z dist:  -0.008488098899471108 m, dof dist:  0.1255253969415046 °\n",
      "Cross Entropy Loss of classifier:  3.2796124143266843\n",
      "Loss in epoch 199:  20240.493792429923\n",
      "Training Dist:  21.486572124500675 m\n",
      "z dist:  -0.0002436956618416808 m, dof dist:  0.12326931484303483 °\n",
      "Cross Entropy Loss of classifier:  3.1012448990590182\n",
      "Cross Entropy Loss of classifier:  3.160700464366539\n",
      "Cross Entropy Loss of classifier:  3.222307846374841\n",
      "Loss in epoch 299:  20240.3900735086\n",
      "Training Dist:  21.486474148498047 m\n",
      "z dist:  -0.00022798967155179817 m, dof dist:  0.12412885221843856 °\n",
      "Cross Entropy Loss of classifier:  3.2834053501119493\n",
      "Cross Entropy Loss of classifier:  3.2223775134386003\n",
      "Cross Entropy Loss of classifier:  3.2222382858808056\n",
      "Cross Entropy Loss of classifier:  3.037399108637665\n",
      "Cross Entropy Loss of classifier:  3.2221398921182205\n",
      "Cross Entropy Loss of classifier:  3.1605372093279183\n",
      "Cross Entropy Loss of classifier:  3.160621218032815\n",
      "Cross Entropy Loss of classifier:  3.0376138035603795\n",
      "Cross Entropy Loss of classifier:  3.2220931702680655\n",
      "Loss in epoch 399:  20240.359087931072\n",
      "Training Dist:  21.486444746412573 m\n",
      "z dist:  -0.00022610267058720268 m, dof dist:  0.12411271121257478 °\n",
      "Cross Entropy Loss of classifier:  3.16054195444202\n",
      "Cross Entropy Loss of classifier:  3.222620167769191\n",
      "Loss in epoch 499:  20240.348282500498\n",
      "Training Dist:  21.486434804645757 m\n",
      "z dist:  -0.00022572693785072317 m, dof dist:  0.12410864906268793 °\n",
      "Loss in epoch 599:  20240.343910144526\n",
      "Training Dist:  21.486430897355834 m\n",
      "z dist:  -0.00022565130463969574 m, dof dist:  0.12410778780698967 °\n",
      "Cross Entropy Loss of classifier:  3.2226019088454487\n",
      "Loss in epoch 699:  20240.34183301409\n",
      "Training Dist:  21.48642894300038 m\n",
      "z dist:  -0.00022563605335257364 m, dof dist:  0.12410760536608023 °\n"
     ]
    }
   ],
   "source": [
    "nAnchors = 25\n",
    "\n",
    "trainDataset = AnchorDataSet(file= f\"./kaggle-data/train/sacre_coeur/traindata_with_features_and_anchors25.pkl\")\n",
    "trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "testDataset = AnchorDataSet(file= f\"./kaggle-data/train/sacre_coeur/testdata_with_features_and_anchors25.pkl\")\n",
    "testDataloader = torch.utils.data.DataLoader(testDataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "myNet = anchorNet(nAnchors=nAnchors).to(device)\n",
    "dofLoss = nn.MSELoss().to(device)\n",
    "crossEntropy = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(myNet.parameters(), lr=0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.5)\n",
    "\n",
    "myAnchors = torch.from_numpy(np.loadtxt(f\"./kaggle-data/train/sacre_coeur/anchors{nAnchors}.txt\")).to(device)\n",
    "\n",
    "epochs = []\n",
    "testXY = []\n",
    "testZ = []\n",
    "testRot = []\n",
    "\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    epochLoss = 0\n",
    "    trainDists = []\n",
    "    zTrain = []\n",
    "    dofTrain = []\n",
    "\n",
    "    for i, data in enumerate(trainDataloader):\n",
    "\n",
    "        myNet.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        myFeats = data[\"Features\"]\n",
    "        myFeats = myFeats.to(device)\n",
    "\n",
    "        myAnchorDistsGt = data[\"anchorDists\"]\n",
    "        myAnchorDistsGt = myAnchorDistsGt.to(device)\n",
    "\n",
    "        myDofGt = data[\"dofs\"]\n",
    "        myDofGt = myDofGt.to(device)\n",
    "\n",
    "        myXyGt = data[\"xy\"]\n",
    "        myXyGt = myXyGt.to(device)\n",
    "\n",
    "        classify, regress, dof_regress = myNet.forward(myFeats)\n",
    "        loss, cEntLoss = custom_loss(classify, regress, dof_regress, anchorDistsGt=myAnchorDistsGt, dofGt=myDofGt, dofLoss=dofLoss, crossEntropy=crossEntropy, factors=[2.4,1.,0.5])\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epochLoss += loss.data.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            bestAnchor = torch.argmax(classify, axis=1).to(device)\n",
    "\n",
    "            dist = 0\n",
    "            dofDist = 0\n",
    "\n",
    "            for j in range(bestAnchor.size()[0]):\n",
    "                dist += torch.linalg.norm(torch.abs((myAnchors[bestAnchor[j], :] - regress.reshape(-1,nAnchors,2)[j,bestAnchor[j], :]) - (myXyGt)[j]))\n",
    "                dofDist += np.mean(Rotation.from_quat(dof_regress[j,1:].cpu().detach().numpy()).as_euler(\"xyz\", degrees=True) - Rotation.from_quat(myDofGt[j,1:].cpu().detach().numpy()).as_euler(\"xyz\",degrees=True))\n",
    "\n",
    "            trainDists.append(dist.data.item() / bestAnchor.size()[0])\n",
    "            zTrain.append(torch.mean(dof_regress[:,0] - myDofGt[:,0]).data.item())\n",
    "            dofTrain.append(dofDist/bestAnchor.size()[0])\n",
    "\n",
    "            \n",
    "    if (epoch+1)%100==0:\n",
    "\n",
    "        print(f\"Loss in epoch {epoch}: \", epochLoss)\n",
    "        print(\"Training Dist: \", np.mean(trainDists),\"m\")\n",
    "        print(\"z dist: \", np.mean(zTrain), \"m, dof dist: \", np.mean(dofTrain), \"°\")\n",
    "\n",
    "    # ===========TESTING=============\n",
    "\n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        epochs.append(epoch)    \n",
    "        testDists = []\n",
    "        zTest = []\n",
    "        dofTest = []\n",
    "\n",
    "        for idx, data in enumerate(testDataloader):\n",
    "\n",
    "            myNet.eval()\n",
    "\n",
    "            myFeats = data[\"Features\"]\n",
    "            myFeats = myFeats.to(device)\n",
    "\n",
    "            myAnchorDistsGt = data[\"anchorDists\"]\n",
    "            myAnchorDistsGt = myAnchorDistsGt.to(device)\n",
    "\n",
    "            myDofGt = data[\"dofs\"]\n",
    "            myDofGt = myDofGt.to(device)\n",
    "\n",
    "            myXyGt = data[\"xy\"]\n",
    "            myXyGt = myXyGt.to(device)\n",
    "\n",
    "            classify, regress, dof_regress = myNet.forward(myFeats)\n",
    "            \n",
    "            bestAnchor = torch.argmax(classify, axis=1).to(device)\n",
    "\n",
    "            dist = 0\n",
    "            dofDist = 0\n",
    "\n",
    "            for j in range(bestAnchor.size()[0]):\n",
    "                dist += torch.linalg.norm(torch.abs((myAnchors[bestAnchor[j], :] - regress.reshape(-1,nAnchors,2)[j,bestAnchor[j], :]) - (myXyGt)[j]))\n",
    "                dofDist += np.mean(Rotation.from_quat(dof_regress[j,1:].cpu().detach().numpy()).as_euler(\"xyz\", degrees=True) - Rotation.from_quat(myDofGt[j,1:].cpu().detach().numpy()).as_euler(\"xyz\",degrees=True))\n",
    "\n",
    "            testDists.append(dist.data.item() / bestAnchor.size()[0])\n",
    "            zTest.append(torch.mean(dof_regress[:,0] - myDofGt[:,0]).data.item())\n",
    "            dofTest.append(dofDist/bestAnchor.size()[0])\n",
    "        \n",
    "        testXY.append(np.mean(testDists))\n",
    "        testZ.append(np.mean(zTest))\n",
    "        testRot.append(np.mean(dofTest))\n",
    "\n",
    "testResults = pd.DataFrame(data={\"Epochs\":epochs, \"XY_dist\":testXY, \"Z_Dist\":testZ,\"angle_error\":testRot})\n",
    "testResults.to_csv(f\"./kaggle-data/train/sacre_coeur/testResults_with_{nAnchors}anchors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('AML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "166128ff86268f1fcb3d3420f8f84010dca90d5eb03cf935b19af5b7f3846e40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
