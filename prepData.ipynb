{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "nAnchors = 24\n",
    "batchSize = 16\n",
    "numEpochs = 3\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats(model, df, fileDir, size=(224,224), outfile=None, nImages=330):\n",
    "    newDf = df.copy()\n",
    "    newDf.loc[:,\"Features\"] = np.zeros((newDf.shape[0], 2208)).tolist()\n",
    "    newDf.loc[:,\"Features\"] = newDf.loc[:,\"Features\"].astype(object)\n",
    "    \n",
    "    # define new index for images where first significant digit is\n",
    "    # sequence number, thus it has to have more overall digits \n",
    "    # than max image number. \n",
    "    newDf.loc[:,\"ImageNum\"] = np.zeros(newDf.shape[0])\n",
    "    indexer = 10**len(str(nImages))\n",
    "    res = torchvision.transforms.Resize(size)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        name = row[\"ImageFile\"].split(\".\")[0]\n",
    "\n",
    "        seq = int(name.split(\"/\")[0].split(\"q\")[-1])\n",
    "        frame = int(name.split(\"frame\")[-1])\n",
    "\n",
    "        newDf.loc[idx, \"ImageNum\"] = indexer*seq + frame\n",
    "\n",
    "        im = res(torch.transpose(torch.transpose(torch.from_numpy(skimage.io.imread(os.path.join(fileDir,row[\"ImageFile\"]))), 1,2),0,1))\n",
    "\n",
    "        # extract features and put through GAP layer                                        \n",
    "        im = im.reshape(1,3,224,224)\n",
    "        x = model.features(im.float())\n",
    "        newDf.at[idx,\"Features\"] = np.squeeze(torch.nn.AvgPool2d(7)(x).detach().numpy())\n",
    "    \n",
    "    newDf.sort_values(\"ImageNum\", inplace=True)\n",
    "\n",
    "    if outfile:\n",
    "        # use pickle format to make sure values of numpy array\n",
    "        # are saved with full accuracy (saving as txt only yields\n",
    "        # around 9 significant digits, pickle saves bit representation)\n",
    "        newDf.to_pickle(outfile)\n",
    "\n",
    "    return newDf\n",
    "\n",
    "def define_anchors(df, nAnchors, outfile=None):\n",
    "    \n",
    "    newDf = df.copy()\n",
    "    newDf.reset_index()\n",
    "    \n",
    "    newDf.loc[:,\"AnchorDists\"] = np.zeros((newDf.shape[0], nAnchors, 2)).tolist()\n",
    "    newDf.loc[:,\"AnchorDists\"] = newDf.loc[:,\"AnchorDists\"].astype(object)\n",
    "\n",
    "    myAnchors = np.zeros((nAnchors, 2))\n",
    "\n",
    "    for i, j in enumerate(np.floor(np.linspace(0,df.shape[0], nAnchors, endpoint=False)).astype(int)):\n",
    "        myAnchors[i,:] = np.array([newDf.loc[j, \"X\"], newDf.loc[j,\"Y\"]])\n",
    "    \n",
    "    for index, row in newDf.iterrows():\n",
    "        newDf.at[index, \"AnchorDists\"] = myAnchors - np.array([newDf.loc[index, \"X\"], newDf.loc[index,\"Y\"]])\n",
    "\n",
    "    if outfile:\n",
    "        newDf.to_pickle(outfile)\n",
    "\n",
    "    return newDf, myAnchors\n",
    "\n",
    "def anchors_for_testSet(df, myAnchors, outfile=None):\n",
    "    # since anchors are only defined on trainings set\n",
    "    newDf = df.copy()\n",
    "\n",
    "    newDf.loc[:,\"AnchorDists\"] = np.zeros((newDf.shape[0], myAnchors.shape[0], 2)).tolist()\n",
    "    newDf.loc[:,\"AnchorDists\"] = newDf.loc[:,\"AnchorDists\"].astype(object)\n",
    "\n",
    "    for index, row in newDf.iterrows():\n",
    "        newDf.at[index, \"AnchorDists\"] = myAnchors - np.array([newDf.loc[index, \"X\"], newDf.loc[index,\"Y\"]])\n",
    "\n",
    "    if outfile:\n",
    "        newDf.to_pickle(outfile)\n",
    "\n",
    "    return newDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use pretrained denseNet\n",
    "myModel = torchvision.models.densenet161(pretrained=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"data/ShopFacade/dataset_train.txt\", delimiter=\" \", skiprows=1)\n",
    "trainData = pd.DataFrame(data={\"ImageFile\": trainData.loc[:,\"ImageFile,\"],\n",
    "                                  \"X\": trainData.Camera,\n",
    "                                  \"Y\": trainData.Position,\n",
    "                                  \"Z\": trainData.loc[:,\"[X\"],\n",
    "                                  \"W\": trainData.Y,\n",
    "                                  \"P\": trainData.Z,\n",
    "                                  \"Q\": trainData.W,\n",
    "                                  \"R\": trainData.P})\n",
    "\n",
    "trainData = extract_feats(myModel, trainData, \"data/ShopFacade/\", outfile=\"data/ShopFacade/traindata_with_features.pkl\")\n",
    "trainData, anch = define_anchors(trainData, nAnchors, f\"data/ShopFacade/traindata_with_features_and_anchors{nAnchors}.pkl\")\n",
    "np.savetxt(f\"data/ShopFacade/anchors{nAnchors}.txt\", anch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"data/ShopFacade/dataset_test.txt\", delimiter=\" \", skiprows=1)\n",
    "testData = pd.DataFrame(data={\"ImageFile\": testData.loc[:,\"ImageFile,\"],\n",
    "                                  \"X\": testData.Camera,\n",
    "                                  \"Y\": testData.Position,\n",
    "                                  \"Z\": testData.loc[:,\"[X\"],\n",
    "                                  \"W\": testData.Y,\n",
    "                                  \"P\": testData.Z,\n",
    "                                  \"Q\": testData.W,\n",
    "                                  \"R\": testData.P})\n",
    "\n",
    "testData = extract_feats(myModel, testData, \"data/ShopFacade/\", outfile=\"data/ShopFacade/testdata_with_features.pkl\")\n",
    "testData = anchors_for_testSet(testData, anch, outfile=f\"data/ShopFacade/testdata_with_features_and_anchors{nAnchors}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ac4e7a3f23f5e168ded2c763f8e15332e6ec0e5cbd319d79cfbd51e5ff4fd43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
