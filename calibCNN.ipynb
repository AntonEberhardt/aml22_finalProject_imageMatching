{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of a CNN trying to guess camera calibrations and transforming to normalized calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clean image data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_covis_filter(fileDir, quantile=0.1, droppedImages = []):\n",
    "\n",
    "    \"\"\"\n",
    "    fileDir: str to directory containing images\n",
    "    quantile: fraction of images that will be dropped\n",
    "    droppedImages: images that have been dropped in previous steps\n",
    "    \"\"\"\n",
    "    fDrops = droppedImages.copy()\n",
    "    df = pd.read_csv(os.path.join(fileDir, \"pair_covisibility.csv\"))\n",
    "\n",
    "    df.insert(len(df.columns), \"name0\", [i.split(\"-\")[0] for i in df.loc[:,\"pair\"]])\n",
    "    df.insert(len(df.columns), \"name1\", [i.split(\"-\")[1] for i in df.loc[:,\"pair\"]])\n",
    "    df.drop(\"pair\",axis=1, inplace=True)\n",
    "\n",
    "    # delete entries of dropped images\n",
    "    for drop in droppedImages:\n",
    "        df = df[np.logical_and(df.loc[:,\"name0\"] != drop, df.loc[:,\"name1\"] != drop)]\n",
    "    \n",
    "    avgCovis = pd.DataFrame(data={\"image\": df.loc[:,\"name0\"].unique(), \"avgCovisibility\": np.zeros(len(df.loc[:,\"name0\"].unique()))})\n",
    "    \n",
    "    for index, row in avgCovis.iterrows():\n",
    "        totalCovis = df[np.logical_or(df.loc[:,\"name0\"] == row[\"image\"], df.loc[:,\"name1\"] == row[\"image\"])].loc[:,\"covisibility\"]\n",
    "        avgCovis.loc[index,\"avgCovisibility\"] = np.mean(totalCovis)\n",
    "    \n",
    "    fDrops += avgCovis[avgCovis.avgCovisibility < avgCovis.avgCovisibility.quantile(quantile)].image.to_list()\n",
    "    avgCovis = avgCovis[avgCovis.avgCovisibility >= avgCovis.avgCovisibility.quantile(quantile)]\n",
    "\n",
    "    return avgCovis, fDrops\n",
    "\n",
    "def distance_filter(fileDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = high_covis_filter(\"./kaggle-data/train/sacre_coeur/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create train and test datasets from resulting selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
